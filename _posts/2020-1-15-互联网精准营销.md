---
layout: post
title: "互联网营销决策"
date: 2020-1-15 9:00:00
categories: [BigData]
excerpt: "大数据实习项目"

---

## 背景介绍

随着互联网不断地推行和普及，大数据给企业营销带来的影响已然不容小觑，大数据精准营销，营销的颠覆性变革同时也证明大数据的实际意义。将来几年，数据营销将有望替代传统营销占据主导地位。大数据精准营销以客户为中央，依托强大的数据库资源，通过对数据的剖析整合，**对客户进行准确的剖析定位，做到适宜的时间、适宜的所在、适宜的价钱、通过适宜的营销渠道，向精确的主顾提供需求的产物**，实现企业效益的最大化。精准营销的本质是依据方向客户的特性化需求计划产物和效劳，而大数据便是花招。大数据技术是电商企业实现精准营销价值的核心技术，大数据下的精准营销也是推动电商企业成功的关键因素。在大数据背景下企业的精准营销应该是“精准营销=精准数据+精准分析+精准推送”，在目前精准营销策略众多的背景下，通过大数据平台的技术支持，对用户数据进行分析，形成“**用户画像**”，通过筛选确定营销客户群体，再通过推荐系统将相关的**商品信息**精准的推送到客户手中已经成为相对成熟的一套精准营销策略。

## 解决方案

1. **确定解决方案**
   1.1 确定营销目标
    提升手机品牌力 ：扩大网络影响范围，提升品牌知名度。
    提升手机销售力：通过用户属性、用户行为、用户评价持续了解受
   众用户，促进更高的销售转化。
    提升产品形象力：配合市场活动、促进用户好感度提升、建立信任
   口碑。
   1.2 **目标人群分析**
   通过构建用户画像或用户人群画像，分析用户群体的购买行为，找
   到用户群体对手机的关注点，定位用户的价值模型。
   1.3 **挖掘用户行为**
   基于可获取的用户行为数据进行挖掘分析，构建用户的行为画像。
   1.4 **锁定目标用户**
   通过上述数据挖掘，锁定用户对手机的关注点、锁定用户的品牌喜
   好、排除非目标用户。
   1.5 **定向精准营销**
   根据构建的用户画像，进行地域精准营销、兴趣精准营销、用户群
   体的精准营销等。
2. **实现思路**
   源数据获取 ---> 数据预处理 ---> **构建用户画像 ---> 数据分析**
   ---> 数据导出 ---> 数据可视化
3. **可行性分析**
   3.1 **源数据获取**
   用户的基本信息、用户的网络行为日志信息较难获取（本案例数据较简
   单维度较少，仅供实验参考）；手机销售的历史数据、用户的评论信息可以
   通过爬虫获取。
   3.2 **数据预处理**
   处理无效值、缺失值、重复值以及保证数据一致性，该过程的清洗方式
   较多，可以实现。
   3.3 **构建用户画像**
   画像构建一般围绕以下两方面：
    显性画像：即用户群体的可视化的特征描述。如目标用户的年龄、
   性别、职业、地域、兴趣爱好等特征
    隐性画像：用户内在的深层次的特征描述。包含了用户的产品使
   用目的、用户偏好、用户需求、产品的使用场景、产品的使用频
   次等。
   注：具体构建维度根据获取的源数据信息确定。
   3.4 **数据分析**
   通过 hiveql 或 sparksql 以及基本算法分析即可达到预期效果。
   3.5 **数据导出**
   数据存储方式较多，如果存储在 hdfs 分布式文件系统即可通过 sqoop
   工具导出到关系库，方便后续可视化。
   3.6 **数据可视化**
   可以通过 Dsight 智慧实验室中提供的 PandaBI 可视化平台进行大屏展示。
4. **确定技术架构**
   4.1 **整体技术架构**
   4.2 **用户画像技术架构**

##  爬取京东手机销售历史数据

 

|      |                                                              |
| ---- | ------------------------------------------------------------ |
|      | ![img](https://mdfileimg.oss-cn-beijing.aliyuncs.com/markdown_pic/clip_image002.jpg) |


本节实验所做内容如下红色标注：



本节实验主要是通过爬虫实现京东手机销售数据的爬取。

 

### 1.     实验工具

 

PyCharm、Sublime Text 等编辑工具

 

### 2.     爬虫流程示意图

 

 

 

 

|      |                                                              |
| ---- | ------------------------------------------------------------ |
|      | ![img](https://mdfileimg.oss-cn-beijing.aliyuncs.com/markdown_pic/clip_image004.gif) |





 

 

 

### **3.**     **爬虫步骤**

 

本实验采用 scrapy 爬虫框架编写爬虫脚本，下面选取核心代码讲解爬取京东手机销售数据的爬取逻辑。具体步骤如下：

3.1  获取电商网站目标数据信息

电商网站上手机基本信息如下：



![img](https://mdfileimg.oss-cn-beijing.aliyuncs.com/markdown_pic/clip_image006.jpg)

3.2 代码编写

(1)  搜索关键词

 

|      |                                                              |
| ---- | ------------------------------------------------------------ |
|      | ![img](https://mdfileimg.oss-cn-beijing.aliyuncs.com/markdown_pic/clip_image008.jpg) |


根据手机品牌作为搜索关键词：



实现代码如下：

```python
with open('./mobile_project/data/手机品牌.csv', 'r',  encoding='utf-8')                     as f: csv_reader = csv.reader(f)                       *# 通过csv按行读取

for brand in csv_reader:

brand = brand[0] print('++++++++++crawling:{}'.format(brand)) if brand.strip():



brand = brand.strip() + '手机'

yield Request(jd_search_url.format(kw=brand, page=page), headers=self.headers,

meta={'kw': brand, 'page': page},

callback=self.parse_search_result)
```

 

 

(2)  获取访问链接

 

|      |                                                              |
| ---- | ------------------------------------------------------------ |
|      | ![img](https://mdfileimg.oss-cn-beijing.aliyuncs.com/markdown_pic/clip_image012.jpg) |


通过电脑网页访问手机端商品详情页，查看商品详情请求的 api：



(3)  明确解析字段

 

|      |                                                              |
| ---- | ------------------------------------------------------------ |
|      | ![img](https://mdfileimg.oss-cn-beijing.aliyuncs.com/markdown_pic/clip_image010.jpg) |





 

 

(4)  解析搜索结果 解析商家信息：

```python
if 'data' in json_data and 'searchm' in json_data['data'] and

json_data['data']['searchm']['Paragraph']:

forn item in json_data['data']['searchm']['Paragraph']:



has_next_page = True

ret = {}

content = item['Content'] ret['name'] = content['warename']

ret['custom_attr_list'] = content['CustomAttrList'] ret['shop_name'] = item['shop_name'] ret['comment_count'] = item['commentcount'] ret['good_rate'] = item['good']

ret['shop_id'] = item['shop_id'] ret['id'] = item['wareid'] ret['price'] = item['dredisprice'] ret['url'] =

'https://item.jd.com/{}.html'.format(item['wareid']) ret['keyword'] = kw

yield Request(jd_wine_info_url.format(skuid=ret['id']), headers=self.headers,

meta=ret, callback=self.parse_product_info)
```

 

 

解析手机详细配置信息：

### 4.解析商品详细配置信息

```python
ret = response.meta

matcher = product_info_ptn.findall(response.text)

if not matcher:

print('*************get product info error') return

json_data = json.loads(matcher[0])

#商品属性信息，这里直接将属性的中文作为key，方便理解！！！

prop_dict = {}

for prop_group in json_data['data']['propGroups']:

for attr i* prop_group['atts']:



prop_dict[attr['attName']] =

'|'.join(attr['vals'])

 

ret['prop'] = prop_dict

yield ret
```

(5)  循环爬取多页数据

(6)  爬取结果存储到 csv 文件

3.3 爬取数据

运行编写完成的 python 脚本，爬取目标数据

 

### 5. 实验成果

 

本次实验完成后，需要得到以下结果：

l 京东手机商品数据爬虫代码编写；

l 爬取数据得到 csv 文件； 爬取结果示例：

```json
{

 

"name":"努比亚 nubia Z18 全面屏 3.0 极夜黑 8GB+128GB 全网通移动联通电信 4G 手机 双卡双待",

"custom_attr_list":"6.0 英寸^8GB^128GB^2400 万+1600 万像素^骁龙

845(SDM845)^800 万像素^2160*1080^8.55",

"shop_name":"努比亚京东自营旗舰店", "comment_count":"13266", "good_rate":"97", "shop_id":"1000001961", "id":"100000047414",

"price":"2549.00",

"url":"https://item.jd.com/100000047414.html", "keyword":"努比亚（nubia） 手机",

"prop":{

"品牌":"努比亚（nubia）",



"型号":"Z18",

"入网型号":"NX606J",

"上市年份":"2018 年",

"上市月份":"9 月",

"机身颜色":"黑色",

"机身长度（mm）":"148.58",

"机身宽度（mm）":"72.54",

"机身厚度（mm）":"8.55",

"机身重量（g）":"172",

"输入方式":"触控",

"运营商标志或内容":"无",

"机身材质分类":"金属边框|玻璃后盖", "屏占比":"91.8%",

"操作系统":"Android",

"操作系统版本":"nubia UI6.0", "CPU 品牌":"骁龙（Snapdragon)", "CPU 频率":"2.8GHz",

"CPU 核数":"八核",

"CPU 型号":"骁龙 845（SDM845）",

"双卡机类型":"双卡双待单通",

"最大支持 SIM 卡数量":"2 个",

"SIM 卡类型":"Nano SIM",

"4G 网络":"4G： 移动（ TD-LTE)|4G： 联通(FDD-LTE)|4G： 电信

(FDD-LTE)|4G：联通(TD-LTE)|电信(TD-LTE)",

"3G/2G 网络":"3G：移动(TD-SCDMA)|3G：联通(WCDMA)|3G：电信(CDMA2000)|2G：移动联通(GSM)+电信(CDMA)",

"副 SIM 卡类型":"Nano SIM",

"副 SIM 卡 4G 网络":"4G：移动（TD-LTE)|4G：联通(FDD-LTE)|4G： 电信(FDD-LTE)|不支持主副卡同时使用电信卡|4G：联通(TD-LTE)",



"4G+（CA）":"移动 4G+|联通 4G+|电信 4G+",

"高清语音通话（VOLTE）":"移动 VOLTE|电信 VOLTE",

"网络频率（2G/3G）":"2G：GSM 850/900/1800/1900|2G：CDMA 800|3G ： TD-SCDMA 1900/2000|3G ： WCDMA 850/900/1900/2100|3G ： CDMA2000|2G： GSM 900/1800|2G： GSM 900/1800/1900|3G： CDMA 800MHz 1X&EVDO|3G：WCDMA：850/900/1700/1900/2100MHz|TD-SCDMA1880/2010",

"是否支持同时使用联通卡":"支持双卡同时在线，并同时使用联通4G 移动数据",

"ROM":"128GB",

"ROM 类型":"UFS",

"RAM":"8GB",

"RAM 类型":"LPDDR 4X",

"存储卡":"不支持",

"主屏幕尺寸（英寸）":"6.0 英寸",

"分辨率":"2160*1080",

"屏幕像素密度（ppi）":"403", "屏幕材质类型":"LTPS",

"屏幕生产厂商":"JDI",

"亮度":"500(type)",

"对比度":"1500（type）",

"前置摄像头":"800 万像素",

"前摄光圈大小":"f/2.0",

"美颜技术":"支持",

"摄像头数量":"2 个",

"后置摄像头":"2400 万+1600 万像素", "摄像头光圈大小":"其他",

"闪光灯":"双色温灯",

"副摄像头光圈大小":"其他",

"拍照特点":"防抖|美颜|连拍|微距|全景|滤镜|场景模式|HDR|PDAF|



微信小视频|水印",

"电池容量（mAh）":"3450",

"电池类型":"锂电池",

"电池是否可拆卸":"否",

"充电器":"9V/2A",

"数据传输接口":"WIFI|NFC|蓝牙|WiFi 热点|OTG 接口",

"NFC/NFC 模式":"支持（点对点模式）|支持（读卡器模式）|支持（卡模式）|支持卡模拟",

"耳机接口类型":"Type-C",

"充电接口类型":"Type-C",

"数据线":"USB2.0",

"指纹识别":"支持",

"语音识别":"支持",

"GPS":"支持",

"电子罗盘":"支持",

"陀螺仪":"支持",

"红外遥控":"不支持",

"其他":"距离感应|呼吸灯|多麦降噪技术|光线感应", "常用功能":"录音|便签|重力感应"

}

}

 
```

选取其中需要的字段输出到 csv 文件：

 

|      |                                                              |
| ---- | ------------------------------------------------------------ |
|      | ![img](https://mdfileimg.oss-cn-beijing.aliyuncs.com/markdown_pic/clip_image014.jpg) |

## **Python 爬取用户评论信息**

 

|      |                                                              |
| ---- | ------------------------------------------------------------ |
|      | ![img](https://mdfileimg.oss-cn-beijing.aliyuncs.com/markdown_pic/clip_image002-1586322845187.jpg) |


本节实验所做内容如下红色标注：



本节实验主要是通过爬虫实现京东用户评论信息的数据爬取。

 

### 1.     实验工具

 

PyCharm、Sublime Text 等编辑工具

 

### 2.     爬虫流程示意图

 

 

 

 

|      |                                                              |
| ---- | ------------------------------------------------------------ |
|      | ![img](https://mdfileimg.oss-cn-beijing.aliyuncs.com/markdown_pic/clip_image004-1586322845188.gif) |





 

 

 

### **3.**     **爬虫步骤**

 

本实验采用 scrapy 爬虫框架编写爬虫脚本，下面选取核心代码讲解爬取京东用户手机评论数据的爬取逻辑。具体步骤如下：

3.1  获取电商网站目标数据信息

电商网站上用户评论信息如下：



![img](https://mdfileimg.oss-cn-beijing.aliyuncs.com/markdown_pic/clip_image006-1586322845188.jpg)

 

3.2 代码编写

(1)  获取用户评论信息的网页链接

通过电脑网页访问手机端用户评论页，查看评论详情请求的 api：

 

|      |                                                              |
| ---- | ------------------------------------------------------------ |
|      | ![img](https://mdfileimg.oss-cn-beijing.aliyuncs.com/markdown_pic/clip_image008-1586322845188.jpg) |





(2)  解析网页内容

```python
json_data = json.decode(matcher[0])  #  必须使用`demjson`模块进行解析。原始json模块解析会出错

for item in json_data['result']['comments']: ret = {}

has_next_page = True ret['id'] = item['id'] ret['keyword'] = product_id
ret['content'] = item['content'] ret['post_at'] = item['creationTime']



ret['image_count'] = item['imageCount'] ret['is_mobile'] = item['isMobile'] ret['mobile_version'] = item['mobileVersion'] ret['user_name'] = item[**'nickname'**] ret['product_color'] = item['productColor'] ret['product_sales'] = |'.join(item['productSales']) ret['product_size'] = item['productSize'] ret['recommend'] = item['recommend'] ret['reply_count'] = item['replyCount'] ret['score'] = item['score']

ret['title'] = item['title']

ret['source'] = item['userClientShow'] ret['user_level'] = item['userLevelName'] yield ret
```

(3)  循环获取多页评论数据

(4)  保存爬虫数据到 csv 文件

3.3 爬取数据

运行编写完成的 python 脚本，爬取目标数据

 

### 4.    实验成果

 

本次实验完成后，需要得到以下结果：

l 京东用户手机评论数据的爬虫代码编写；

l 爬取数据得到 csv 文件； 爬取结果示例：

```json
{

 

"id":"11909216182", "keyword":"100000047414",

"content":"电池超耐用玩王者荣耀不卡手机不发热，手机反应速

度快",



"post_at":"2018-09-14 15:37:03",

"image_count":"0", "is_mobile":true, "mobile_version":"7.0.2", "user_name":"jd_087534", "product_color":" 极 夜 黑 ", "product_sales":"", "product_size":"8GB+128GB", "recommend":"true",

"reply_count":"2",

"score":"5",

"title":"",

"source":"来自京东 Android 客户端", "user_level":"钻石会员"

}
```

 

保存爬取数据到 csv 文件：

 

|      |                                                              |
| ---- | ------------------------------------------------------------ |
|      | ![img](https://mdfileimg.oss-cn-beijing.aliyuncs.com/markdown_pic/clip_image010-1586322845189.jpg) |

 

##  kettle 实现源数据的预处理

 

### 一、目的

 

l 熟练使用 kettle 工具做数据预处理；

l 掌握 kettle 中常用步骤的配置；

l 能按清洗目标准确实现数据清洗工作；

 

### 二、环境

 

Kettle7.0

 

### 三、步骤

 

 

|      |                                                              |
| ---- | ------------------------------------------------------------ |
|      | ![img](https://mdfileimg.oss-cn-beijing.aliyuncs.com/markdown_pic/clip_image002-1586323109583.jpg) |


 本节实验所做内容如下红色标注：



 

本节实验主要是通过 kettle 实现源数据的预处理。**具体实验步骤如下：**

#### \1.  下载安装 kettle7.0 工具

#### \2.  运行 Spoon.bat 文件启动 kettle



![img](https://mdfileimg.oss-cn-beijing.aliyuncs.com/markdown_pic/clip_image004.jpg)

 

#### \3.  新建转换去除手机销售信息表的重复记录

 

|      |                                                              |
| ---- | ------------------------------------------------------------ |
|      | ![img](https://mdfileimg.oss-cn-beijing.aliyuncs.com/markdown_pic/clip_image008-1586323109584.jpg) |





 

#### \4.  在上述转换的基础上清洗手机销售信息表中型号字段中的数据

**要求**：去除该字段中的所有空格，方便后续聚合统计，字母统一大小写， 去除该字段中的所有特殊字符（各种标点符号）

#### \5.  新建转换去除用户评论信息表的重复记录



![img](https://mdfileimg.oss-cn-beijing.aliyuncs.com/markdown_pic/clip_image006-1586323109584.jpg)

 

#### \6.  新建转换处理用户信息表中出生日期字段（将 2019 年 5 月 20 日转换为2019-5-20）

 

|      |                                                              |
| ---- | ------------------------------------------------------------ |
|      | ![img](https://mdfileimg.oss-cn-beijing.aliyuncs.com/markdown_pic/clip_image010-1586323109584.jpg) |





#### \7.  在每个转换中的文本文件输出步骤中，指定分隔符为英文状态下的逗号， 去除输出文件的表头数据，编码格式保持一致，最终的编码格式为 utf-8。

![img](https://mdfileimg.oss-cn-beijing.aliyuncs.com/markdown_pic/clip_image012-1586323109584.jpg)



### 四、成果

 

本次实验完成后，需要得到以下结果：

l 去除手机销售信息表的重复记录；

l 去除用户评论表的重复记录；

l 清洗手机销售信息表中型号字段数据（同一型号数据格式保持一致）；

l 对用户信息表中的出生日期字段进行格式处理；

l 清洗完成后保存为文本文件；



##  Hive 加载电商源数据

### 一、目的

 

l 掌握 hive 建库、建表语句；

l 掌握 hive 加载数据的几种方式；

l 熟练 hive 表数据的常用查询语句；

 

### 二、环境

 

Dsight 智慧实验室中的 hadoop 环境

 

### 三、步骤

 

本节实验所做内容如下红色标注：

 

|      |                                                              |
| ---- | ------------------------------------------------------------ |
|      | ![img](https://mdfileimg.oss-cn-beijing.aliyuncs.com/markdown_pic/clip_image002-1586323377989.jpg) |





 

本节实验主要是通过 Hive 加载本地源数据到 hdfs 分布式文件系统。**具体实验步骤如下：**

#### \1.  进入实验室，打开 hadoop 环境



![img](https://mdfileimg.oss-cn-beijing.aliyuncs.com/markdown_pic/clip_image004-1586323377989.jpg)

 

#### \2.  启动 hive 进程

![img](https://mdfileimg.oss-cn-beijing.aliyuncs.com/markdown_pic/clip_image006-1586323377989.jpg)第一次进入实验环境时启动方式：cd /etc/init.d 运 行./hive-start.sh 之后进入实验室环境时 输入 hive，回车即可。

 

 

 

 

 

 

 

 

 

#### \3.  创建数据库

create database databasename;

建议创建自己的数据库，默认使用 default 数据也可。

#### \4.  使用数据库

use databasename;

创建数据库后，需要使用数据库才能在该数据库下进行建表、加载数据等后续操作。如果没有使用数据库，默认使用 default 数据库。

#### \5.  创建表

创建用户基本信息表、手机销售信息表、用户评价表、用户行为表。

#### \6.  加载数据

通过 hive 加载本地数据的方式依次加载上述表中的源数据。

#### \7.  查询加载的数据



通过已学的查询语句查询加载后的数据，保证加载数据能正常显示，若出现乱码及 时修改数据编码格式。

#### \8.  处理手机销售信息表数据

**说明：**由于爬虫过程是通过关键词搜索获取的，所获取数据不仅包含手机的销售数 据，此外，关于手机的部分外设（充电宝、数据线、手机膜、保护壳、耳机等）销 售数据，需要将这部分数据清洗掉。可根据手机销售信息表中的操作系统字段筛选。

**要求**：筛选手机的销售数据存储到新表。

 

|      |                                                              |
| ---- | ------------------------------------------------------------ |
|      | ![img](https://mdfileimg.oss-cn-beijing.aliyuncs.com/markdown_pic/clip_image008-1586323377989.jpg) |





#### \9.  处理用户行为表数据

**要求：**将用户行为源表中交易月份与交易日拼接为新字段存储到新表。

 

|      |                                                              |
| ---- | ------------------------------------------------------------ |
|      | ![img](https://mdfileimg.oss-cn-beijing.aliyuncs.com/markdown_pic/clip_image010-1586323377989.jpg) |





#### \10.  处理用户信息表数据

**要求：**关联用户评论表和用户信息表将用户等级、用户年龄段划分后存入新表。

1 表示年龄<18

2 表示年龄在[18,24]

3 表示年龄在[25,29]

4 表示年龄在[30,34]



5 表示年龄在[35,39]

6 表示年龄在[40,49]

7 表示年龄>=50

 

|      |                                                              |
| ---- | ------------------------------------------------------------ |
|      | ![img](https://mdfileimg.oss-cn-beijing.aliyuncs.com/markdown_pic/clip_image012-1586323377990.jpg) |


新表数据字段说明：



 

### 四、成果

 

本次实验完成后，需要得到以下结果：

l 创建自己的数据库；

l 创建用户基本信息表并加载数据；

l 创建京东手机销售信息表并加载数据；

l 创建用户评价信息表并加载数据；

l 创建用户基本行为信息表并加载数据；

l 按要求处理手机销售表、用户信息表、用户行为表的数据；

 

## **基于** **Spark** **构建用户画像**

 

### 一、目的

 

l 了解什么是用户画像；

l 熟悉用户画像的开发流程；

l 了解电商用户画像如何构建；

l 熟悉使用 Hive、Spark SQL 进行数据开发；

 

### 二、环境

 

Dsight 智慧实验室中的 hadoop 实验环境

 

### 三、步骤

 

本节实验所做内容如下红色标注：

 

 

 

|      |                                                              |
| ---- | ------------------------------------------------------------ |
|      | ![img](https://mdfileimg.oss-cn-beijing.aliyuncs.com/markdown_pic/clip_image002-1586328049834.jpg) |





 

本节实验主要是通过 sparksql 整合 hive 实现用户画像的标签开发。**具体实验步骤如下：**



#### 1.   用户画像介绍

 

用户画像的核心工作是为用户打标签，打标签的重要目的之一是为了让人能够理解并且方便计算机处理，如，可以做分类统计：喜欢 iphone 的用户有多少？ 喜欢 iphone 的人群中，男、女比例是多少？也可以做数据挖掘工作：利用聚类算法分析，喜欢 iphone 的人年龄段分布情况。

 

#### 2.   构建用户画像

 

##### 2.1 标签的命名

 

|      |                                                              |
| ---- | ------------------------------------------------------------ |
|      | ![img](https://mdfileimg.oss-cn-beijing.aliyuncs.com/markdown_pic/clip_image004-1586328049834.jpg) |





 

**标签主题：**用于刻画属于那种类型的标签，如用户属性、用户行为、用户消费、风险控 制等多种类型，可用 A、B、C、D 等字母表示各标签主题；

 

**标签类型：**标签类型可划为分类型和统计型这两种类型，其中分类型用于刻画用户属于 哪种类型，如是男是女、是否是会员、是否已流失等标签，统计型标签用于刻画统计用  户的某些行为次数，如收藏次数、近 30 日购买次数等标签，这类标签都需要对应一个 用户相应行为的权重次数；

 

**开发方式：**开发方式可分为统计型开发和算法型开发两大开发方式。其中统计型开发可 直接从数据仓库中各主题表建模加工而成，算法型开发需要对数据做机器学习的算法处  理得到相应的标签；

 

**是否互斥标签：**对应同一级类目下（如一级标签、二级标签），各标签之间的关系是否 为互斥，可将标签划分为互斥关系和非互斥关系。例如对于男、女标签就是互斥关系，  同一个用户不是被打上男性标签就是女性标签，对于高活跃、中活跃、低活跃标签也是 互斥关系；



**用户维度：**用于刻画该标签是打在用户唯一标识（userid）上，还是打在用户使用的设 备（cookieid）上或其他的唯一标识。可用 U、C 等字母分别标识 userid和 cookieid 维度。

 

示例：对于用户是男是女这个标签，标签主题是用户属性，标签类型属于分类型，开发 方式为统计型，为互斥关系，用户维度为 userid。这样给男性用户打上“A111U001_001”， 女性用户打上标签“A111U001_002”，其中“A111U” 为上面介绍的命名 方式，“001”为一 级标签的 id，后面对于用户属性维度的其他一级标签可用“002”、“003” 等方式追加 命名，“_”后面的“001” 和“002”为该一级标签下的标签明细，如果是划分高、中、低活 跃用户的， 对应一级标签下的明细可划分为“001”、“002”、“003”。

 

|      |                                                              |
| ---- | ------------------------------------------------------------ |
|      | ![img](https://mdfileimg.oss-cn-beijing.aliyuncs.com/markdown_pic/clip_image006-1586328049834.jpg) |





 

 

> ## 注：本案例中标签主题为用户属性和用户行为；开发方式以统计性开发为主； 用户维 度使用 userid 为唯一标识。

 

##### 2.2 用户基本属性的标签开发

 

**用户属性标签**：根据用户所填写的属性开发的标签和推算出来的标签（暂时不考虑）。用于了解用户的人口属性的基本情况和按不同属性维度统计。

 

**主要数据来源**：用户基本信息表



**标签开发的技术工具**：sparksql 整合 hive，通过 python 编写 sparksql 代码保存为 xxx.py 可执行文件，在 hadoop 环境中的 spark 组件中运行.py 文件

**步骤：**

**1.启动**hive **的** **metastroe** **后台进程**

**进入** **hive** **安装目录** **cd /opt/hive**    **执行** **bin/hive --service metastore **

**2.运行.py** **文件**

**cd /opt/spark**

**执行** **bin/spark-submit /data/xx/xxx.py (.py** **文件的全路径**)

 

**开发实现：**这里首先确定用户属性标签表的表结构，包含哪些字段，这些字段都是什么 数据类型，用户属性表创建代码如下：

 

```sql
drop table if exists dwd person_user_tag_attribute; create table dwd person_user_tag_attribute

(

 

user_id string comment '用户编码', tag_id string comment ' 标 签 id', tag_name string comment '标签名称',

tag_type string comment '标签类型（主题）'

 

)
```

 

comment '用户画像-用户属性标签表'；

 

根据用户的源数据信息，可以创建以下几个用户属性标签表： 用户性别标签表



![img](https://mdfileimg.oss-cn-beijing.aliyuncs.com/markdown_pic/clip_image008-1586328049834.jpg)

 

 

用户年龄段标签表

 

|      |                                                              |
| ---- | ------------------------------------------------------------ |
|      | ![img](https://mdfileimg.oss-cn-beijing.aliyuncs.com/markdown_pic/clip_image010-1586328049834.jpg) |





 

用户会员标签表

 

 

|      |                                                              |
| ---- | ------------------------------------------------------------ |
|      | ![img](https://mdfileimg.oss-cn-beijing.aliyuncs.com/markdown_pic/clip_image012-1586328049835.jpg) |







##### 2.3 用户行为的标签开发

 

**用户行为标签**：是根据用户在产品上的访问行为、下单行为提取用户标签， 用于定位用 户在产品上的访问情况，进而根据用户的浏览习惯、消费偏好做推荐和营销。

 

**主要数据来源**：用户行为表

> 注：在项目工程实践中，数据主要来源于业务类数据表、日志数据表和埋点数据表，本次案例真实数据无法获取，简单模拟了用户的基本行为数据包括（点击、加入购物 车、购买、关注商品）

 

**标签开发的技术工具：**和用户属性标签开发相同**开发实现：**

（1）开发用户行为标签表

 

```sql
drop table if exists dwd person_user_tag_action; 
create table dwd person_user_tag_action( user_id string comment '用户编码', tag_id string comment ' 标 签 id', tag_name string comment '标签名称', tag_type string comment '标签类型', action_count int comment '行为次数')
```

comment '用户画像-用户行为标签表';

 

根据用户行为表信息，通过 sql 语句创建以用户行为标签表并加载数据

 

 

|      |                                                              |
| ---- | ------------------------------------------------------------ |
|      | ![img](https://mdfileimg.oss-cn-beijing.aliyuncs.com/markdown_pic/clip_image002-1586329053839.jpg) |





 

### 四、实验成果

 

本次实验完成后，需要得到以下结果：

 

l 开发用户性别标签表

l 开发用户年龄标签表

l 开发用户等级标签表

l 开发用户行为标签表

##  单品销售分析

 

本节实验所做内容如下红色标注：

 

 

|      |                                                              |
| ---- | ------------------------------------------------------------ |
|      | ![img](https://mdfileimg.oss-cn-beijing.aliyuncs.com/markdown_pic/clip_image004-1586329053840.jpg) |





 

### 本节实验主要是通过 Hive ql 语句进行手机单品分析

**具体实验步骤如下：**

#### \1.  进入 hadoop 环境，启动 hive,进入自定义数据库

#### \2.  基于手机销售新表，统计各手机品牌销量 top10： Hql 语句统计 TopN 并建表，表字段包含：



手机品牌、销售量：

 

|      |                                                              |
| ---- | ------------------------------------------------------------ |
|      | ![img](https://mdfileimg.oss-cn-beijing.aliyuncs.com/markdown_pic/clip_image006-1586329053840.jpg) |





#### \3.  统计某品牌的各型号手机的销量

（1）  统计华为手机品牌下各单品销量 Top20：（方便后续大屏展示） 选择手机销售信息表中的手机品牌（查询条件为华为）、销售量字段

作为新表字段，查询并建表。

 

|      |                                                              |
| ---- | ------------------------------------------------------------ |
|      | ![img](https://mdfileimg.oss-cn-beijing.aliyuncs.com/markdown_pic/clip_image008-1586329053840.jpg) |





（2）  统计苹果手机品牌下各单品销量 Top20（方便后续大屏展示）： 选择手机销售信息表中的手机品牌（查询条件为苹果和 Apple）、销售量字段作为新表字段，查询并建表。

 

|      |                                                              |
| ---- | ------------------------------------------------------------ |
|      | ![img](https://mdfileimg.oss-cn-beijing.aliyuncs.com/markdown_pic/clip_image010-1586329053840.jpg) |





#### \4.  统计用户各年龄段手机销量

（1）关联查询新用户信息表、用户评论表、手机销量表生成新 hive 表， 统计各年龄段的手机销量。生成的新表包含的字段：

用户年龄段、单品手机类型、销量数量

 

|      |                                                              |
| ---- | ------------------------------------------------------------ |
|      | ![img](https://mdfileimg.oss-cn-beijing.aliyuncs.com/markdown_pic/clip_image012-1586329053840.jpg) |





#### \5.  统计各地区用户手机销量

（1）关联用户信息表、用户评价表、手机销量表生成新表，新表包含的字段：

用户地区、手机单品类型、销售量

 

|      |                                                              |
| ---- | ------------------------------------------------------------ |
|      | ![img](https://mdfileimg.oss-cn-beijing.aliyuncs.com/markdown_pic/clip_image002-1586329406896.jpg) |







### 四、实验成果

 

本次实验完成后，需要得到以下结果：

l 统计手机品牌销量 Top10；

l 统计华为手机单品销量排行 Top20；

l 统计苹果手机单品销量排行 Top20；

l 统计用户各年龄段手机销售情况；

l 统计各地区用户手机销售情况；



 

##  **用户行为画像分析**

 

 

### 一、目的

 

l 了解用户行为标签权重的计算方法；

l 了解用户的各标签表的关联合并；

l 了解用户行为权重标记对营销的意义； 

### 二、步骤

 

本节实验所做内容如下红色标注：

 

|      |                                                              |
| ---- | ------------------------------------------------------------ |
|      | ![img](https://mdfileimg.oss-cn-beijing.aliyuncs.com/markdown_pic/clip_image004-1586329406896.jpg) |





 

 

本节实验主要是对用户行为标签表加工生成用户行为权重表，并将该表与用户属性标签表进行关联形成宽表供后续分析使用。

具体步骤如下：



#### **1.**  **用户行为权重值的计算**

 

##### 1.1 行为权重介绍

 

|      |                                                              |
| ---- | ------------------------------------------------------------ |
|      | ![img](https://mdfileimg.oss-cn-beijing.aliyuncs.com/markdown_pic/clip_image006-1586329406896.jpg) |





一个用户标签表里面包括常见的字段如：用户 id、用户姓名、标签id、标签名称、用户与该标签发生行为的次数（如搜索了两次“大数据” 这个关键词）、行为类型（不同的行为类型对应用户对商品不同的意愿强度，如购买某商品>收藏某商品>关注某商品>点击某商品），行为时间（越久远的时间对用户当前的影响越小，如 5 年前你会点击某三星手机，而现在你会点击华为或苹果）。最后非常重要的一个字段是标签权重，该权重影响着对用户属性的归类，属性归类不准确，接下来基于画像对用户进行推荐、营销的准确性也就无从谈起了。

##### 1.2 权重的计算

> 用户标签权重 = 行为类型权重 * 时间衰减 * TF-IDF 计算得到每个用户身上的标签权重 * 行为次数

v 行为类型权重：一般而言操作复杂度越高的行为权重越大。该权重值一般由运营人员或数据分析人员主观给出；

自定义购买权重为 5，加入购物车权重为 4，关注权重为 3，点击权重为 2

v 时间衰减：时间衰减是指用户的行为会随着时间的过去，历史行为和当前的相关性不断减弱。

套用牛顿冷却定律数学模型：

> F(t)=初始温度×exp(-冷却系数×间隔的时间)

"冷却系数"是一个你自己决定的值。如果假定手机的的初始点击次数是 5 次，24 小时之后"冷却"为 1 次，那么可以计算得到"冷却系数"约等于0.067。如果你想放 慢更新率，" 冷却系数"就取一个较小的值，否则就取一个较大的值。

v TF-IDF 计算标签权重：



![img](https://mdfileimg.oss-cn-beijing.aliyuncs.com/markdown_pic/clip_image008-1586329406896.jpg)

 

|      |                                                              |
| ---- | ------------------------------------------------------------ |
|      | ![img](https://mdfileimg.oss-cn-beijing.aliyuncs.com/markdown_pic/clip_image010-1586329406896.jpg) |





 

根据 TF * IDF 即可得到该用户该标签的权重值

 

#### 2.  新建用户行为权重表并加载数据

 

在用户行为标签表的基础上，新建用户行为权重表用户行为标签权重表结构设计：

```sql
drop table if exists dwd act_weight_detail; create table dwd act_weight_detail

(

user_id string comment '用户编码', tag_id string comment ' 标 签 id', tag_name string comment '标签名称', cnt int comment ' 行 为 次 数 ', tag_type_id int comment '标签类型',

act_weight_detail float comment '行为权重'

)

co
```

mment '用户画像-用户行为标签权重表';

加载数据：同步用户行为标签表中的数据以及添加权重值到该表中。

 

#### 3.  生成宽表

 

根据用户id 关联用户所有属性标签表和用户行为权重表生成新的宽表并加载数据

表结构设计：



```sql
drop table if exists profile_user_tb; create table profile_user_tb

(

user_id string comment ' 用 户 编 码 ', tag_id1 string comment ' 标 签 1 ID', tag_name1 string comment '标签 1 名称', tag_type1 string comment '标签 1 类型', tag_id2 string comment ' 标 签 2 ID', tag_name2 string comment '标签 2 名称', tag_type2 string comment '标签 2 类型', tag_id3 float comment ' 标 签 3 ID', tag_name3 string comment '标签 3 名称', tag_type3 string comment '标签 3 类型', tag_id4 string comment ' 标 签 4 ID', tag_name4 string comment '标签 4 名称',

action_count bigint comment '标签 4 行为次数', action_weight decimal(38,7)  comment '标签 4 权重', tag_type4 string comment '标签 4 类型'

)
```

comment '用户画像-用户标签宽表';

 

|      |                                                              |
| ---- | ------------------------------------------------------------ |
|      | ![img](https://mdfileimg.oss-cn-beijing.aliyuncs.com/markdown_pic/clip_image002-1586329991757.jpg) |







### 三、成果

 

本次实验完成后，需要得到以下结果：

l 创建用户行为标签权重表并加载数据；

l 关联合并用户属性标签表和用户行为权重表；





## **中文分词实现用户评价分析**

本节实验所做内容如下红色标注：

 

|      |                                                              |
| ---- | ------------------------------------------------------------ |
|      | ![img](https://mdfileimg.oss-cn-beijing.aliyuncs.com/markdown_pic/clip_image004-1586329991757.jpg) |





 

 

本节实验主要是通过 python 自然语言分析算法对用户评论信息进行分词统计，将统计结果保存到 hive 中。

### 具体实验步骤如下：

#### \1.    规范用户评价信息



 

|      |                                                              |
| ---- | ------------------------------------------------------------ |
|      | ![img](https://mdfileimg.oss-cn-beijing.aliyuncs.com/markdown_pic/clip_image006-1586329991757.jpg) |


只取评价内容，保存成新的 txt 文件（分隔符保持一致）



#### \2.    编写代码实现中文分词

（1） 开发语言：python

（2） 运行环境：hadoop 环境中的 python 环境

（3） 读取源文本文件内容

```
content = **"" try**:

fo = open(filename)

print("****读取文件名：****", filename)

for line in fo.readlines():

content += line.strip() print("****字数：", len(content))
```

（4） 使用结巴分词组件做中文分词

```
rawContent = readFile(rawFileName)
```



> r = '[0-9\s+\.\!\/_,$%^*()?;；:-【】+\"\']+|[+——！，;：。？、**~@#**￥%……&\*（）]+'

```
rawContent = re.sub(r, **" "**, rawContent) seg_list = jieba.cut(rawContent, cut_all=**False**) writeFile(dataFileName, **" "**.join(seg_list))
```

（5） 分词结果进行词频统计



```python
with open(dataFileName) as wf, open(sortFileName,'w') as wf2, open(tmpFileName, 'w') as wf3:

 
for word in wf:

word_lst.append(word.split(' ')) for item in word_lst:

for item2 in item:

if item2 not in word_dict:

word_dict[item2] = 1

 else:

word_dict[item2] += 1
```



（6） 词频统计结果写入新的 txt 文件word_items.sort(reverse = **True**) **for** item **in** word_items:

wf2.write(item.label+**' '**+str(item.times) + **'\n'**)

 

 

#### \3.    运行编写好的 python 脚本，得到词频统计结果文本文件

 

|      |                                                              |
| ---- | ------------------------------------------------------------ |
|      | ![img](https://mdfileimg.oss-cn-beijing.aliyuncs.com/markdown_pic/clip_image002-1586331353064.jpg) |





#### \4.    新建 hive 表加载词频统计结果数据

```sql
drop table if exists comment_word_count_tb; create table comment_word_count_tb(

word string, count int

)

row format delimited fields terminated by ' ';



load     data     local     inpath     '/xxx/result.txt'     into        table comment_word_count_tb;
```



#### \5.    查看数据是否保存成功

 

### 四、成果

 

本次实验完成后，需要得到以下结果：

l 实现用户评价信息中的中文分词；

l 实现中文分词后的词频统计；

在 hive 中新建词频统计表加载分词

## **Hive ql** **实现价格、时间段销量分析** 

### 一、目的

 

l 掌握 Hql 语句的编写；

l 了解时间段和价格两个指标的分析方法；

 

### 二、环境

 

Dsight 智慧实验室的 hadoop 环境

 

### 三、步骤

 

本节实验所做内容如下红色标注：

 

 

|      |                                                              |
| ---- | ------------------------------------------------------------ |
|      | ![img](https://mdfileimg.oss-cn-beijing.aliyuncs.com/markdown_pic/clip_image004-1586331353064.jpg) |





 

本节实验主要是通过 Hive ql 语句实现各时间段、各价格区间手机销量的统计。

#### **具体步骤如下：**

#### \1.    划分时间段统计手机销量

（1）  新建时间段手机销量表表结构设计：



```sql
drop table if exists date_range_sail_count; create table date_range_sail_count

(

date_range string comment '交易时间段', sail_count int comment '手机销量'

)
```

comment '各时间段手机销量表';

（2）  编辑 Hql 语句关联查询数据并插入新表关联手机销售信息表和用户行为表

 

|      |                                                              |
| ---- | ------------------------------------------------------------ |
|      | ![img](https://mdfileimg.oss-cn-beijing.aliyuncs.com/markdown_pic/clip_image006-1586331680309.jpg) |


各时间段销量表字段、数据：



#### \2.    划分价格区间统计手机销量

（1） 新建价格区间中间表，存储手机销量、价格区间

<1000  1000 元以下

[1000,2000] 1000-2000 元

[2001,3000]  2000-3000 元

[3001-5000] 3000-5000 元

[5001-8000] 5000-8000 元

[8001-10000]   8000-10000 元

\>10000 10000 元以上

（2） 在中间表基础上计算销量并存储到价格区间手机销量结果表表结构设计：

```sql
drop table if exists price_range_sail_count; create table price_range_sail_count

(



price_range string comment '价格区间', sail_count int comment '手机销量'

)
```

comment '各价格区间手机销量表';

（3） 编辑 Hql 语句计算并查询数据插入结果表

 

|      |                                                              |
| ---- | ------------------------------------------------------------ |
|      | ![img](https://mdfileimg.oss-cn-beijing.aliyuncs.com/markdown_pic/clip_image008-1586331680309.jpg) |





 

### 四、成果

 

本次实验完成后，需要得到以下结果：

l 统计不同时间段手机销量；

l 统计不同价格区间手机销量；



## **Sqoop** **实现分析数据的导出** 

#### 一、目的

 

l 掌握 sqoop 工具导出数据的使用方法；

l 熟练编写 sqoop export 命令；

l 熟练使用 Danastudio 平台建 postgres 表；

 

#### 二、环境

 

Dsight 智慧实验室的 hadoop 环境

Danastudio 平台

 

#### 三、步骤

 

本节实验所做内容如下红色标注：

 

 

|      |                                                              |
| ---- | ------------------------------------------------------------ |
|      | ![img](https://mdfileimg.oss-cn-beijing.aliyuncs.com/markdown_pic/clip_image002-1586332015958.jpg) |





 

本节实验主要是通过 Sqoop 工具将分析结果数据导出到 postgres 关系库中， 方便后续大屏可视化。

##### 具体实验步骤如下：

###### \1.  关系库 postgres 中目标表的创建



新建手机品牌热销 Top10 表、华为手机单品销量 Top20 表、苹果手机单品销量Top20 表、用户评论热词统计表、各地区手机销量表、各时间段手机销量表、各价格区间手机销量表、用户标签宽表

1.1  启动 Danastudio

 

|      |                                                              |
| ---- | ------------------------------------------------------------ |
|      | ![img](https://mdfileimg.oss-cn-beijing.aliyuncs.com/markdown_pic/clip_image004-1586332015959.jpg) |


在 Dsight 实验室打开 danastudio 环境，进入 danastudio



1.2  新增数据源和目标表

点击数据中心 --->  模型管理 ---> 新增

 

|      |                                                              |
| ---- | ------------------------------------------------------------ |
|      | ![img](https://mdfileimg.oss-cn-beijing.aliyuncs.com/markdown_pic/clip_image006-1586331353064.jpg) |





选择存储源（student+自己学号或 teacher+工号,存储源名称即目标数据库名） ---> 数据层选择 student-stork 或 teacher-stork ---> 类型、模式选择默认 ---> 模型名（即目标表名）---> 按导出字段添加字段 ---> 点击下边的完成按钮即可。

> 注：导出的字段和目标表的字段要一致

###### \2.  Sqoop export 导出命令的编写

Ø 编写导出各年龄段手机销售数据的 sqoop 命令：

```
bin/sqoop export \



--connect jdbc:postgresql://192.168.50.78:14103/teacher123 \

--username stork \

--password stork \

--table age_region_sail_info \

--export-dir /data/hive/warehouse/sail.db/age_region_sail_info \

--input-fields-terminated-by ','
```



> ## 注：
>
> **192.168.50.78****：****Postgres** **主机地址（****Danastudio IP** **地址）**
>
> **14103****：****Postgres** **固定** **IP**
>
> **teacher123****：****postgres** **数据库名称****（****danastudio** **中存储源的名称，****student+** **学号或** **teacher+****工号）**
>
> **--export-dir             /data/hive/warehouse/sail.db/age_range_sail_count** **数 据****存储路径， 可以通过以下命令查询：**
>
> **show create table age_range_sail_count;**
>
> Ø 按照以上方式编写 sqoop 脚本导出其他几张表的数据

###### \3.  执行 Sqoop 脚本导出数据

（1）               进入 sqoop 目录下：cd /opt/sqoop

（2）               执行导出命令

```
bin/sqoop export \

--connect jdbc:postgresql://192.168.50.78:14103/teacher123    \

--username stork \

--password stork \

--table age_region_sail_info\

--export-dir /data/hive/warehouse/sail.db/age_region_sail_info\

--input-fields-terminated-by ','
```

出现以下信息表示导出成功：



![img](https://mdfileimg.oss-cn-beijing.aliyuncs.com/markdown_pic/clip_image004-1586331680309.jpg)

 

#### 四、实验成果

 

本次实验完成后，需要得到以下结果：

l 导出用户各年龄段销量表数据到 postgres；

l 导出各地区手机单品销量数据到 postgres；

l 导出手机销量 Top10 表中数据到 postgres；

l 导出华为手机单品销量 Top20 数据到 postgres；

l 导出苹果手机单品销量 Top20 数据到 postgres；

l 导出各时间段手机销量数据到 postgres；

l 导出各价格区间手机销量数据到 postgres；

l 导出用户评论词频统计 Top200 数据到 postgres；

l 导出用户标签宽表数据到 postgres；

## 基于 PandaBI 的数据可视化

 

### 一、目的

 

l 了解 PandaBI 平台的基本使用；

l 掌握 PandaBI 制作数据大屏的方法；

 

### 二、环境

 

Dsight 智慧实验室的 PandaBI 平台

 

### 三、步骤

 

本节实验所做内容如下红色标注：

 

|      |                                                              |
| ---- | ------------------------------------------------------------ |
|      | ![img](https://mdfileimg.oss-cn-beijing.aliyuncs.com/markdown_pic/clip_image002-1586331680308.jpg) |





 

本节实验主要是通过 PandaBI 可视化平台连接存储分析结果数据的 postgres

关系库，制作多维度可视化大屏。**具体实验步骤如下：**

#### \1. 进入 Dsight 实验室，开启 PandaBI 可视化平台



![img](https://mdfileimg.oss-cn-beijing.aliyuncs.com/markdown_pic/clip_image006-1586332015959.jpg)

#### \2. 连接 postgres 数据库

 

|      |                                                              |
| ---- | ------------------------------------------------------------ |
|      | ![img](https://mdfileimg.oss-cn-beijing.aliyuncs.com/markdown_pic/clip_image002-1586332130900.jpg) |


点击数据源 ---> 添加数据源 ---> 选择数据源类型 stork ---> 编辑数据库连接 ---> 连接测试 ---> 测试成功后添加



#### \3. 创建工作表

根据关系库中存储的结果数据表，创建制作图表需要的工作表，如下图所示：

 

|      |                                                              |
| ---- | ------------------------------------------------------------ |
|      | ![img](https://mdfileimg.oss-cn-beijing.aliyuncs.com/markdown_pic/clip_image010-1586332015959.jpg) |





#### \4. 制作数据大屏

（1）   点击数据大屏，可创建属于自己的文件夹，在该文件夹下创建自己



的数据大屏；

 

|      |                                                              |
| ---- | ------------------------------------------------------------ |
|      | ![img](https://mdfileimg.oss-cn-beijing.aliyuncs.com/markdown_pic/clip_image008-1586332015959.jpg) |





（2）   点击编辑，进入大屏编辑页面，选择图表开始创建，所有图表创建完成后，可添加标题文字。

![img](https://mdfileimg.oss-cn-beijing.aliyuncs.com/markdown_pic/clip_image014-1586328049835.jpg)

 

 

### 四、成果

 

本次实验完成后，需要得到以下结果：

l 完成用户人群分析模块的数据大屏；

l 完成用户评论热词的数据大屏；

l 完成单品分析的数据大屏；

l 完成各时间段手机销量数据大屏；

l 完成手机价格区间销量数据大屏； 制作完成的数据大屏示例：

## **根据分析结果决定营销方案**



### 一、目标

 

l 了解数据大屏分析的意义；

l 了解多维度数据关联分析的重要性；

l 了解根据数据分析结果制定营销方案的方法；

 

### 二、数据分析及指导

 

以下是实验中得出的用户画像数据：

 

|      |                                                              |
| ---- | ------------------------------------------------------------ |
|      | ![img](https://mdfileimg.oss-cn-beijing.aliyuncs.com/markdown_pic/clip_image012-1586332015959.jpg) |





 

以下是 PandaBI 平台制作的各图表组成的数据仪表盘，根据下图分析数据之间的简单关联；



![img](https://mdfileimg.oss-cn-beijing.aliyuncs.com/markdown_pic/clip_image004-1586332130900.jpg)

 

根据上述图表分析数据的指导意义及营销方案的制定：

\1.  图一是京东平台手机热销品牌 Top10 排行，其中华为、苹果、小米



这三个大家熟知的品牌销量占比最大。

\2.  图二和图三是实验中选取的销量前二的两个手机品牌进行的单品销量统计数据。可以看到华为品牌中荣耀 8x（10.15%）、荣耀 9 青春版（7.99%）、荣耀 v10（7.79%）、荣耀畅玩 7x（7.8%）、荣耀 10（7.79%）的销量占比接 近一半。说明华为荣耀型号的手机销量都较好。苹果品牌中 iphone X（21.72%） 和 iphone8（21.09%）销量占比 42.81%。可以结合时间段单品销量分析什么时间什么型号的手机销量较好，精准确定手机营销方案。

\3.  图四是某年京东平台各时间段手机销量变化趋势，其中总销量为63787101 部，可以直观的看到 11-11 当天的销量 9761076 部，占比为 15.30%。可以根据销量最好的手机品牌及手机单品类型在双 11 等特殊时间段制定相关营销方案促进商品营销。

\4.  图五是各价格区间手机销量，可以看到 1000 元以下以及 1000-2000 元的手机在京东平台销量最佳，我们可以结合手机热销单品具体确定哪款手机受欢迎度最高。

\5.  图六、图十、图十一是在用户角度统计不同属性指标的手机销售数据，统计的总用户为 47875 人次。京东平台用户性别比例接近，男性用户占45.2%，女性用户占 54.8%；18-30 岁的用户占比超过一半，其中 18-24 岁销量占比 29.32%，25-29 岁销量占比 25.05%；用户会员等级集中到铜牌会员和银牌会员。我们可以结合实验中的用户画像数据分析每个用户的会员等级与年龄分布情况以及用户行为数据之间的关系，针对每个用户实现精准营销。

\6.  图七是手机单品各地区销量分布情况，分布越密集的区域说明该区域某手机单品销量越好。在制定营销方案时可考虑分区域销售某手机单品

（比如华为荣耀 v10、iphoneX 等）实现精准营销。

\7.  图八是用户评论信息中 Top200 热词统计，从热词统计中可以分析用户对手机的哪些方面比较重视；可以看到服务、质量、屏幕、充电、价格、电池、声音、物流、耳机、手感、颜色、系统、外观等词出现次数很多，说明用户比较关心手机的各方面功能以及京东服务质量、物流等。根据热词分析商家或厂商可以作出相应的调整。

\8.  图九是用户行为统计数据，包括点击、加入购物车、购买、关注四



种行为。真正项目中的用户日志无法获取，所以用户行为方面做简单的分析即可，可以结合实验中得出的用户画像数据分析每个用户的各种行为权重， 从而确定该用户的价值模型。

\9.  可以根据用户画像数据挖掘用户的价值，结合用户行为权重以及用户会员等级，在数据充足的情况下也可结合用户收入水平、消费水平构建用户价值模型，可以划分为重要价值用户、重要保持用户、重要发展用户、重要挽留用户、一般价值用户、一般保持用户、一般发展用户、一般挽留用户等多个价值模型。在后续制定营销方案时根据该模型实现每位用户的精准推荐。
