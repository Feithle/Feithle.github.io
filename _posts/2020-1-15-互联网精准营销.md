---
layout: post
title: "互联网营销决策"
date: 2020-1-15 9:00:00
categories: [BigData]
excerpt: "大数据实习项目"

---

## 背景介绍

随着互联网不断地推行和普及，大数据给企业营销带来的影响已然不容小觑，大数据精准营销，营销的颠覆性变革同时也证明大数据的实际意义。将来几年，数据营销将有望替代传统营销占据主导地位。大数据精准营销以客户为中央，依托强大的数据库资源，通过对数据的剖析整合，**对客户进行准确的剖析定位，做到适宜的时间、适宜的所在、适宜的价钱、通过适宜的营销渠道，向精确的主顾提供需求的产物**，实现企业效益的最大化。精准营销的本质是依据方向客户的特性化需求计划产物和效劳，而大数据便是花招。大数据技术是电商企业实现精准营销价值的核心技术，大数据下的精准营销也是推动电商企业成功的关键因素。在大数据背景下企业的精准营销应该是“精准营销=精准数据+精准分析+精准推送”，在目前精准营销策略众多的背景下，通过大数据平台的技术支持，对用户数据进行分析，形成“**用户画像**”，通过筛选确定营销客户群体，再通过推荐系统将相关的**商品信息**精准的推送到客户手中已经成为相对成熟的一套精准营销策略。

## 解决方案

1. **确定解决方案**
   1.1 确定营销目标
    提升手机品牌力 ：扩大网络影响范围，提升品牌知名度。
    提升手机销售力：通过用户属性、用户行为、用户评价持续了解受
   众用户，促进更高的销售转化。
    提升产品形象力：配合市场活动、促进用户好感度提升、建立信任
   口碑。
   1.2 **目标人群分析**
   通过构建用户画像或用户人群画像，分析用户群体的购买行为，找
   到用户群体对手机的关注点，定位用户的价值模型。
   1.3 **挖掘用户行为**
   基于可获取的用户行为数据进行挖掘分析，构建用户的行为画像。
   1.4 **锁定目标用户**
   通过上述数据挖掘，锁定用户对手机的关注点、锁定用户的品牌喜
   好、排除非目标用户。
   1.5 **定向精准营销**
   根据构建的用户画像，进行地域精准营销、兴趣精准营销、用户群
   体的精准营销等。
2. **实现思路**
   源数据获取 ---> 数据预处理 ---> **构建用户画像 ---> 数据分析**
   ---> 数据导出 ---> 数据可视化
3. **可行性分析**
   3.1 **源数据获取**
   用户的基本信息、用户的网络行为日志信息较难获取（本案例数据较简
   单维度较少，仅供实验参考）；手机销售的历史数据、用户的评论信息可以
   通过爬虫获取。
   3.2 **数据预处理**
   处理无效值、缺失值、重复值以及保证数据一致性，该过程的清洗方式
   较多，可以实现。
   3.3 **构建用户画像**
   画像构建一般围绕以下两方面：
    显性画像：即用户群体的可视化的特征描述。如目标用户的年龄、
   性别、职业、地域、兴趣爱好等特征
    隐性画像：用户内在的深层次的特征描述。包含了用户的产品使
   用目的、用户偏好、用户需求、产品的使用场景、产品的使用频
   次等。
   注：具体构建维度根据获取的源数据信息确定。
   3.4 **数据分析**
   通过 hiveql 或 sparksql 以及基本算法分析即可达到预期效果。
   3.5 **数据导出**
   数据存储方式较多，如果存储在 hdfs 分布式文件系统即可通过 sqoop
   工具导出到关系库，方便后续可视化。
   3.6 **数据可视化**
   可以通过 Dsight 智慧实验室中提供的 PandaBI 可视化平台进行大屏展示。
4. **确定技术架构**
   4.1 **整体技术架构**
   4.2 **用户画像技术架构**

##  爬取京东手机销售历史数据

 

|      |                                                              |
| ---- | ------------------------------------------------------------ |
|      | ![img](https://mdfileimg.oss-cn-beijing.aliyuncs.com/markdown_pic/clip_image002.jpg) |


本节实验所做内容如下红色标注：



本节实验主要是通过爬虫实现京东手机销售数据的爬取。

 

### 1.     实验工具

 

PyCharm、Sublime Text 等编辑工具

 

### 2.     爬虫流程示意图

 

 

 

 

|      |                                                              |
| ---- | ------------------------------------------------------------ |
|      | ![img](https://mdfileimg.oss-cn-beijing.aliyuncs.com/markdown_pic/clip_image004.gif) |





 

 

 

### **3.**     **爬虫步骤**

 

本实验采用 scrapy 爬虫框架编写爬虫脚本，下面选取核心代码讲解爬取京东手机销售数据的爬取逻辑。具体步骤如下：

3.1  获取电商网站目标数据信息

电商网站上手机基本信息如下：



![img](https://mdfileimg.oss-cn-beijing.aliyuncs.com/markdown_pic/clip_image006.jpg)

3.2 代码编写

(1)  搜索关键词

 

|      |                                                              |
| ---- | ------------------------------------------------------------ |
|      | ![img](https://mdfileimg.oss-cn-beijing.aliyuncs.com/markdown_pic/clip_image008.jpg) |


根据手机品牌作为搜索关键词：



实现代码如下：

```
with** open(**'./mobile_project/data/****手机品牌****.csv'**, **'r'**,  encoding=**'utf-8'**)                     **as** f: csv_reader = csv.reader(f)                       *#* *通**过**csv* *按行读**取*

**for** brand **in** csv_reader:

brand = brand[0] print(**'++++++++++crawling:{}'**.format(brand)) **if** brand.strip():



brand = brand.strip() + **'** **手机'**

**yield** Request(jd_search_url.format(kw=brand, page=page), headers=self.headers,

meta={**'kw'**: brand, **'page'**: page},

callback=self.parse_search_result)
```

 

 

(2)  获取访问链接

 

|      |                                                              |
| ---- | ------------------------------------------------------------ |
|      | ![img](https://mdfileimg.oss-cn-beijing.aliyuncs.com/markdown_pic/clip_image012.jpg) |


通过电脑网页访问手机端商品详情页，查看商品详情请求的 api：



(3)  明确解析字段

 

|      |                                                              |
| ---- | ------------------------------------------------------------ |
|      | ![img](https://mdfileimg.oss-cn-beijing.aliyuncs.com/markdown_pic/clip_image010.jpg) |





 

 

(4)  解析搜索结果 解析商家信息：

```
if** **'data'** **in** json_data **and 'searchm' in** json_data[**'data'**] **and**

json_data[**'data'**][**'searchm'**][**'Paragraph'**]:

**for** item **in** json_data[**'data'**][**'searchm'**][**'Paragraph'**]:



has_next_page = **True**

ret = {}

content = item[**'Content'**] ret[**'name'**] = content[**'warename'**]

ret[**'custom_attr_list'**] = content[**'CustomAttrList'**] ret[**'shop_name'**] = item[**'shop_name'**] ret[**'comment_count'**] = item[**'commentcount'**] ret[**'good_rate'**] = item[**'good'**]

ret[**'shop_id'**] = item[**'shop_id'**] ret[**'id'**] = item[**'wareid'**] ret[**'price'**] = item[**'dredisprice'**] ret[**'url'**] =

**'https://item.jd.com/{}.html'**.format(item[**'wareid'**]) ret[**'keyword'**] = kw

**yield** Request(jd_wine_info_url.format(skuid=ret[**'id'**]), headers=self.headers,

meta=ret, callback=self.parse_product_info)
```

 

 

解析手机详细配置信息：

### 4.解析商品详细配置信息

```
ret = response.meta

matcher = product_info_ptn.findall(response.text)

**if not** matcher:

print('*************get product info error') return

json_data = json.loads(matcher[0])

*#* *商品属性信息，这里直接将属性的中文作为**key**，方便理解！！！*

prop_dict = {}

**for** prop_group **in** json_data[**'data'**][**'propGroups'**]:

**for** attr **in** prop_group[**'atts'**]:



prop_dict[attr[**'attName'**]] =

**'|'**.join(attr[**'vals'**])

 

ret[**'prop'**] = prop_dict

**yield** ret
```

(5)  循环爬取多页数据

(6)  爬取结果存储到 csv 文件

3.3 爬取数据

运行编写完成的 python 脚本，爬取目标数据

 

### 5. 实验成果

 

本次实验完成后，需要得到以下结果：

l 京东手机商品数据爬虫代码编写；

l 爬取数据得到 csv 文件； 爬取结果示例：

```json
{

 

"name":"努比亚 nubia Z18 全面屏 3.0 极夜黑 8GB+128GB 全网通移动联通电信 4G 手机 双卡双待",

"custom_attr_list":"6.0 英寸^8GB^128GB^2400 万+1600 万像素^骁龙

845(SDM845)^800 万像素^2160*1080^8.55",

"shop_name":"努比亚京东自营旗舰店", "comment_count":"13266", "good_rate":"97", "shop_id":"1000001961", "id":"100000047414",

"price":"2549.00",

"url":"https://item.jd.com/100000047414.html", "keyword":"努比亚（nubia） 手机",

"prop":{

"品牌":"努比亚（nubia）",



"型号":"Z18",

"入网型号":"NX606J",

"上市年份":"2018 年",

"上市月份":"9 月",

"机身颜色":"黑色",

"机身长度（mm）":"148.58",

"机身宽度（mm）":"72.54",

"机身厚度（mm）":"8.55",

"机身重量（g）":"172",

"输入方式":"触控",

"运营商标志或内容":"无",

"机身材质分类":"金属边框|玻璃后盖", "屏占比":"91.8%",

"操作系统":"Android",

"操作系统版本":"nubia UI6.0", "CPU 品牌":"骁龙（Snapdragon)", "CPU 频率":"2.8GHz",

"CPU 核数":"八核",

"CPU 型号":"骁龙 845（SDM845）",

"双卡机类型":"双卡双待单通",

"最大支持 SIM 卡数量":"2 个",

"SIM 卡类型":"Nano SIM",

"4G 网络":"4G： 移动（ TD-LTE)|4G： 联通(FDD-LTE)|4G： 电信

(FDD-LTE)|4G：联通(TD-LTE)|电信(TD-LTE)",

"3G/2G 网络":"3G：移动(TD-SCDMA)|3G：联通(WCDMA)|3G：电信(CDMA2000)|2G：移动联通(GSM)+电信(CDMA)",

"副 SIM 卡类型":"Nano SIM",

"副 SIM 卡 4G 网络":"4G：移动（TD-LTE)|4G：联通(FDD-LTE)|4G： 电信(FDD-LTE)|不支持主副卡同时使用电信卡|4G：联通(TD-LTE)",



"4G+（CA）":"移动 4G+|联通 4G+|电信 4G+",

"高清语音通话（VOLTE）":"移动 VOLTE|电信 VOLTE",

"网络频率（2G/3G）":"2G：GSM 850/900/1800/1900|2G：CDMA 800|3G ： TD-SCDMA 1900/2000|3G ： WCDMA 850/900/1900/2100|3G ： CDMA2000|2G： GSM 900/1800|2G： GSM 900/1800/1900|3G： CDMA 800MHz 1X&EVDO|3G：WCDMA：850/900/1700/1900/2100MHz|TD-SCDMA1880/2010",

"是否支持同时使用联通卡":"支持双卡同时在线，并同时使用联通4G 移动数据",

"ROM":"128GB",

"ROM 类型":"UFS",

"RAM":"8GB",

"RAM 类型":"LPDDR 4X",

"存储卡":"不支持",

"主屏幕尺寸（英寸）":"6.0 英寸",

"分辨率":"2160*1080",

"屏幕像素密度（ppi）":"403", "屏幕材质类型":"LTPS",

"屏幕生产厂商":"JDI",

"亮度":"500(type)",

"对比度":"1500（type）",

"前置摄像头":"800 万像素",

"前摄光圈大小":"f/2.0",

"美颜技术":"支持",

"摄像头数量":"2 个",

"后置摄像头":"2400 万+1600 万像素", "摄像头光圈大小":"其他",

"闪光灯":"双色温灯",

"副摄像头光圈大小":"其他",

"拍照特点":"防抖|美颜|连拍|微距|全景|滤镜|场景模式|HDR|PDAF|



微信小视频|水印",

"电池容量（mAh）":"3450",

"电池类型":"锂电池",

"电池是否可拆卸":"否",

"充电器":"9V/2A",

"数据传输接口":"WIFI|NFC|蓝牙|WiFi 热点|OTG 接口",

"NFC/NFC 模式":"支持（点对点模式）|支持（读卡器模式）|支持（卡模式）|支持卡模拟",

"耳机接口类型":"Type-C",

"充电接口类型":"Type-C",

"数据线":"USB2.0",

"指纹识别":"支持",

"语音识别":"支持",

"GPS":"支持",

"电子罗盘":"支持",

"陀螺仪":"支持",

"红外遥控":"不支持",

"其他":"距离感应|呼吸灯|多麦降噪技术|光线感应", "常用功能":"录音|便签|重力感应"

}

}

 
```

选取其中需要的字段输出到 csv 文件：

 

|      |                                                              |
| ---- | ------------------------------------------------------------ |
|      | ![img](https://mdfileimg.oss-cn-beijing.aliyuncs.com/markdown_pic/clip_image014.jpg) |

## **Python 爬取用户评论信息**

 

|      |                                                              |
| ---- | ------------------------------------------------------------ |
|      | ![img](E:\Program Files\Typora\upload\clip_image002-1586322845187.jpg) |


本节实验所做内容如下红色标注：



本节实验主要是通过爬虫实现京东用户评论信息的数据爬取。

 

### 1.     实验工具

 

PyCharm、Sublime Text 等编辑工具

 

### 2.     爬虫流程示意图

 

 

 

 

|      |                                                              |
| ---- | ------------------------------------------------------------ |
|      | ![img](E:\Program Files\Typora\upload\clip_image004-1586322845188.gif) |





 

 

 

### **3.**     **爬虫步骤**

 

本实验采用 scrapy 爬虫框架编写爬虫脚本，下面选取核心代码讲解爬取京东用户手机评论数据的爬取逻辑。具体步骤如下：

3.1  获取电商网站目标数据信息

电商网站上用户评论信息如下：



![img](E:\Program Files\Typora\upload\clip_image006-1586322845188.jpg)

 

3.2 代码编写

(1)  获取用户评论信息的网页链接

通过电脑网页访问手机端用户评论页，查看评论详情请求的 api：

 

|      |                                                              |
| ---- | ------------------------------------------------------------ |
|      | ![img](E:\Program Files\Typora\upload\clip_image008-1586322845188.jpg) |





(2)  解析网页内容

json_data = json.decode(matcher[0])  *#*   *必须使用**`demjson`**模块进**行解析。原始**json* *模块解析会出错*

**for** item **in** json_data[**'result'**][**'comments'**]: ret = {}

has_next_page = **True** ret[**'id'**] = item[**'id'**] ret[**'keyword'**] = product_id

ret[**'content'**] = item[**'content'**] ret[**'post_at'**] = item[**'creationTime'**]



ret[**'image_count'**] = item[**'imageCount'**] ret[**'is_mobile'**] = item[**'isMobile'**] ret[**'mobile_version'**] = item[**'mobileVersion'**] ret[**'user_name'**] = item[**'nickname'**] ret[**'product_color'**] = item[**'productColor'**] ret[**'product_sales'**] = **'|'**.join(item[**'productSales'**]) ret[**'product_size'**] = item[**'productSize'**] ret[**'recommend'**] = item[**'recommend'**] ret[**'reply_count'**] = item[**'replyCount'**] ret[**'score'**] = item[**'score'**]

ret[**'title'**] = item[**'title'**]

ret[**'source'**] = item[**'userClientShow'**] ret[**'user_level'**] = item[**'userLevelName'**] **yield** ret

(3)  循环获取多页评论数据

(4)  保存爬虫数据到 csv 文件

3.3 爬取数据

运行编写完成的 python 脚本，爬取目标数据

 

### 4.    实验成果

 

本次实验完成后，需要得到以下结果：

l 京东用户手机评论数据的爬虫代码编写；

l 爬取数据得到 csv 文件； 爬取结果示例：

{

 

"id":"11909216182", "keyword":"100000047414",

"content":"电池超耐用玩王者荣耀不卡手机不发热，手机反应速

度快",



"post_at":"2018-09-14 15:37:03",

"image_count":"0", "is_mobile":true, "mobile_version":"7.0.2", "user_name":"jd_087534", "product_color":" 极 夜 黑 ", "product_sales":"", "product_size":"8GB+128GB", "recommend":"true",

"reply_count":"2",

"score":"5",

"title":"",

"source":"来自京东 Android 客户端", "user_level":"钻石会员"

}

 

保存爬取数据到 csv 文件：

 

|      |                                                              |
| ---- | ------------------------------------------------------------ |
|      | ![img](E:\Program Files\Typora\upload\clip_image010-1586322845189.jpg) |
